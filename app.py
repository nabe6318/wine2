import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from io import BytesIO

from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder

st.set_page_config(page_title="ãƒ¯ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿æ±ºå®šæœ¨ï¼ˆCSV/Streamlitï¼‰", layout="wide")
st.title("ğŸ· æ±ºå®šæœ¨ å¯è¦–åŒ–ã‚¢ãƒ—ãƒªï¼ˆCSVå¯¾å¿œ / Streamlit Cloudï¼‰")

st.markdown("""
- å·¦å´ã§ CSV ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ç›®çš„å¤‰æ•°ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰ã¨ç‰¹å¾´é‡ï¼ˆèª¬æ˜å¤‰æ•°ï¼‰ã‚’é¸ã³ã¾ã™  
- `Graphviz` ã¯ä¸è¦ï¼ˆStreamlit Cloud ã§å‹•ä½œï¼‰  
- æ±ºå®šæœ¨ã®**PNGç”»åƒ**ã¨**Graphviz DOT**ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½
""")

# ---------- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ----------
def encode_features(df: pd.DataFrame, feature_cols):
    """ç‰¹å¾´é‡ã®éæ•°å€¤åˆ—ã‚’ LabelEncoder ã§æ•°å€¤åŒ–ï¼ˆå­¦ç¿’ç”¨ï¼‰ã€‚æˆ»ã‚Šå€¤: X, encoders(dict)"""
    X = df[feature_cols].copy()
    encoders = {}
    for col in feature_cols:
        if not pd.api.types.is_numeric_dtype(X[col]):
            le = LabelEncoder()
            X[col] = le.fit_transform(X[col].astype(str))
            encoders[col] = le
    return X, encoders

def encode_target(y_series: pd.Series):
    """ç›®çš„å¤‰æ•°ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã€‚ã‚«ãƒ†ã‚´ãƒª/å°‘æ•°é›¢æ•£å€¤ã¯ LabelEncoderã€ãã‚Œä»¥å¤–ã¯ãã®ã¾ã¾ï¼ˆåˆ†é¡å‰æã®ãƒã‚§ãƒƒã‚¯åˆ¥ï¼‰ã€‚"""
    class_names = None
    y_encoder = None

    # ç›®çš„å¤‰æ•°ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°
    nunique = y_series.nunique(dropna=True)

    # éæ•°å€¤ã¯ LabelEncode
    if not pd.api.types.is_numeric_dtype(y_series):
        y_encoder = LabelEncoder()
        y = y_encoder.fit_transform(y_series.astype(str))
        class_names = [str(c) for c in y_encoder.classes_]
        return y, y_encoder, class_names

    # æ•°å€¤ã ãŒã€Œé›¢æ•£ã£ã½ã„ã€å ´åˆï¼ˆã‚¯ãƒ©ã‚¹æ•°ãŒå¤šã™ããªã„ï¼‰
    if nunique <= 20:
        # 0..K-1ã«ä¸¦ã³æ›¿ãˆ
        classes_sorted = sorted(y_series.dropna().unique())
        mapping = {v: i for i, v in enumerate(classes_sorted)}
        y = y_series.map(mapping).values
        y_encoder = None
        class_names = [str(c) for c in classes_sorted]
        return y, y_encoder, class_names

    # é€£ç¶šå€¤ã£ã½ã„ï¼ˆåˆ†é¡æœ¨ã«ã¯ä¸å‘ãï¼‰
    return None, None, None

# ---------- ãƒ‡ãƒ¼ã‚¿å…¥åŠ› ----------
with st.sidebar:
    st.header("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å…¥åŠ›")
    uploaded = st.file_uploader("CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ˜ãƒƒãƒ€è¡Œã‚ã‚Šæƒ³å®šï¼‰", type=["csv"])
    use_sample = st.checkbox("ã‚µãƒ³ãƒ—ãƒ«ï¼ˆsklearn wineï¼‰ã‚’ä½¿ã†", value=(uploaded is None))

if use_sample:
    # sklearnã®ãƒ¯ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾DataFrameåŒ–
    from sklearn.datasets import load_wine
    wine = load_wine(as_frame=True)
    df = wine.frame.copy()  # features + target
    # target åã¯æ•°å€¤ã€‚åˆ¥é€”åå‰ãƒªã‚¹ãƒˆã¯ wine.target_names
    st.caption("ã‚µãƒ³ãƒ—ãƒ«ï¼šsklearn wine ãƒ‡ãƒ¼ã‚¿")
else:
    if uploaded is None:
        st.info("CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    df = pd.read_csv(uploaded)

st.subheader("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
st.dataframe(df.head(), use_container_width=True)
st.write(f"è¡Œæ•°: **{len(df)}**  åˆ—æ•°: **{df.shape[1]}**")

# ---------- åˆ—é¸æŠ ----------
all_cols = df.columns.tolist()
if len(all_cols) < 2:
    st.error("åˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚CSVã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

default_target = "target" if "target" in all_cols else all_cols[-1]
target_col = st.selectbox("ğŸ¯ ç›®çš„å¤‰æ•°ï¼ˆåˆ†é¡ã‚¯ãƒ©ã‚¹ï¼‰", all_cols, index=all_cols.index(default_target))

feature_candidates = [c for c in all_cols if c != target_col]

# ã€Œå…¨é¸æŠ/å…¨è§£é™¤ã€ãƒœã‚¿ãƒ³ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ä¿æŒï¼‰
if "feature_selection" not in st.session_state:
    st.session_state.feature_selection = feature_candidates.copy()

col_a, col_b = st.columns(2)
with col_a:
    if st.button("ğŸŸ© å…¨ç‰¹å¾´é‡ã‚’é¸æŠ"):
        st.session_state.feature_selection = feature_candidates.copy()
with col_b:
    if st.button("â¬œ å…¨è§£é™¤"):
        st.session_state.feature_selection = []

selected_features = st.multiselect(
    "ğŸ§® ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ï¼ˆè¤‡æ•°é¸æŠï¼‰",
    options=feature_candidates,
    default=st.session_state.feature_selection,
    key="feature_selection",
)

if len(selected_features) == 0:
    st.warning("å°‘ãªãã¨ã‚‚1ã¤ã®ç‰¹å¾´é‡ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚")
    st.stop()

# æ¬ æå‡¦ç†ï¼ˆç°¡æ˜“ï¼‰ï¼šç›®çš„å¤‰æ•°ã¨é¸æŠç‰¹å¾´é‡ã«æ¬ æãŒã‚ã‚‹è¡Œã‚’é™¤å¤–
work_df = df[selected_features + [target_col]].dropna()
dropped = len(df) - len(work_df)
if dropped > 0:
    st.caption(f"âš ï¸ æ¬ æã‚’å«ã‚€ {dropped} è¡Œã‚’å‰Šé™¤ã—ã¾ã—ãŸï¼ˆå­¦ç¿’å¯¾è±¡ {len(work_df)} è¡Œï¼‰ã€‚")

# ç›®çš„å¤‰æ•°ã®é€£ç¶šå€¤ãƒã‚§ãƒƒã‚¯ & ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
y_raw = work_df[target_col]
y, y_encoder, class_names = encode_target(y_raw)

if y is None:
    st.error("ç›®çš„å¤‰æ•°ãŒé€£ç¶šå€¤ï¼ˆã‚¯ãƒ©ã‚¹æ•°ãŒå¤šã™ãï¼‰ã«è¦‹ãˆã¾ã™ã€‚åˆ†é¡æœ¨ã«ã¯**ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°**ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

X, x_encoders = encode_features(work_df, selected_features)

# ---------- ãƒ¢ãƒ‡ãƒ«è¨­å®š ----------
st.sidebar.header("ğŸ› ï¸ ãƒ¢ãƒ‡ãƒ«è¨­å®š")
criterion = st.sidebar.selectbox("ä¸ç´”åº¦æŒ‡æ¨™", ["gini", "entropy", "log_loss"], index=0)
max_depth = st.sidebar.slider("æœ€å¤§æ·±ã•ï¼ˆ0=åˆ¶é™ãªã—ï¼‰", 0, 20, 3)
test_size = st.sidebar.slider("ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚ºï¼ˆå‰²åˆï¼‰", 0.1, 0.5, 0.2, step=0.05)
random_state = st.sidebar.number_input("random_state", 0, 9999, 0, step=1)
use_class_weight = st.sidebar.checkbox("ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–ï¼ˆclass_weight='balanced')", value=False)

depth = None if max_depth == 0 else max_depth
class_weight = "balanced" if use_class_weight else None

# ---------- å­¦ç¿’ ----------
X_train, X_test, y_train, y_test = train_test_split(
    X.values, y, test_size=test_size, random_state=random_state, stratify=y
)

clf = DecisionTreeClassifier(
    criterion=criterion,
    max_depth=depth,
    random_state=random_state,
    class_weight=class_weight,
)
clf.fit(X_train, y_train)

# ---------- è©•ä¾¡ ----------
y_pred = clf.predict(X_test)
acc = accuracy_score(y_test, y_pred)

st.subheader("ğŸ“Š è©•ä¾¡")
st.write(f"**Accuracy:** {acc:.4f}")

rep = classification_report(y_test, y_pred, target_names=class_names, output_dict=False, zero_division=0)
st.code(rep)

# æ··åŒè¡Œåˆ—ï¼ˆç”»åƒï¼‰
cm = confusion_matrix(y_test, y_pred, labels=list(range(len(class_names))))
fig_cm, ax_cm = plt.subplots(figsize=(4 + 0.4*len(class_names), 4 + 0.4*len(class_names)))
im = ax_cm.imshow(cm, interpolation="nearest")
ax_cm.set_title("Confusion Matrix")
ax_cm.set_xticks(range(len(class_names)))
ax_cm.set_yticks(range(len(class_names)))
ax_cm.set_xticklabels(class_names, rotation=45, ha="right")
ax_cm.set_yticklabels(class_names)
for (i, j), v in np.ndenumerate(cm):
    ax_cm.text(j, i, str(v), ha='center', va='center')
fig_cm.colorbar(im, ax=ax_cm, fraction=0.046, pad=0.04)
st.pyplot(fig_cm, use_container_width=True)

# ---------- æ±ºå®šæœ¨ã®å¯è¦–åŒ–ï¼ˆmatplotlibï¼‰ ----------
st.subheader("ğŸŒ³ æ±ºå®šæœ¨ï¼ˆmatplotlibï¼‰")
fig, ax = plt.subplots(figsize=(min(24, 1.2*len(selected_features)+8), 8))
plot_tree(
    clf,
    feature_names=selected_features,
    class_names=class_names,
    filled=True,
    rounded=True,
    impurity=True,
    fontsize=10,
    ax=ax
)
st.pyplot(fig, use_container_width=True)

# PNG ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
buf = BytesIO()
fig.savefig(buf, format="png", bbox_inches="tight", dpi=200)
png_bytes = buf.getvalue()
st.download_button(
    "ğŸ“¥ æ±ºå®šæœ¨PNGã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
    data=png_bytes,
    file_name="decision_tree.png",
    mime="image/png"
)

# Graphviz DOT æ–‡å­—åˆ—ï¼ˆç”»åƒåŒ–ã¯ã—ãªã„ãŒã€å¾Œã§ä½¿ãˆã‚‹ï¼‰
dot_str = export_graphviz(
    clf,
    out_file=None,
    feature_names=selected_features,
    class_names=class_names,
    filled=True,
    rounded=True,
    special_characters=True
)
st.download_button(
    "ğŸ“¥ Graphviz DOT ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
    data=dot_str.encode("utf-8"),
    file_name="decision_tree.dot",
    mime="text/plain"
)

# ---------- é‡è¦åº¦ ----------
st.subheader("ğŸ·ï¸ ç‰¹å¾´é‡ã®é‡è¦åº¦")
importances = clf.feature_importances_
imp_df = pd.DataFrame({"feature": selected_features, "importance": importances}).sort_values("importance", ascending=False)
st.dataframe(imp_df, use_container_width=True)

fig_imp, ax_imp = plt.subplots(figsize=(8, max(3, 0.4*len(selected_features))))
ax_imp.barh(imp_df["feature"], imp_df["importance"])
ax_imp.invert_yaxis()
ax_imp.set_xlabel("Importance")
st.pyplot(fig_imp, use_container_width=True)

# ---------- ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã®æ³¨æ„ ----------
with st.expander("â„¹ï¸ ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã®å¯¾å¿œï¼ˆè‡ªå‹•å‡¦ç†ã®èª¬æ˜ï¼‰"):
    st.markdown("""
- æ–‡å­—åˆ—ã®**ç‰¹å¾´é‡**ã¯ LabelEncoder ã«ã‚ˆã‚Š 0..K-1 ã«è‡ªå‹•å¤‰æ›ã—ã¦ã„ã¾ã™  
- ç›®çš„å¤‰æ•°ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰ãŒæ–‡å­—åˆ—ãªã‚‰è‡ªå‹•ã§ã‚¯ãƒ©ã‚¹ã«å¤‰æ›ã—ã¾ã™  
- ç›®çš„å¤‰æ•°ãŒæ•°å€¤ã§ã‚‚ã‚¯ãƒ©ã‚¹æ•°ãŒ20ä»¥ä¸‹ãªã‚‰**é›¢æ•£ã‚¯ãƒ©ã‚¹**ã¨ã¿ãªã—ã¦å­¦ç¿’ã—ã¾ã™  
- **å¤šæ•°ã®é€£ç¶šå€¤**ãŒã‚ã‚‹ç›®çš„å¤‰æ•°ã¯åˆ†é¡æœ¨ã«ä¸å‘ãã§ã™ï¼ˆå›å¸°æœ¨ã‚’ä½¿ã†ã®ãŒæœ›ã¾ã—ã„ï¼‰
""")
    if y_encoder is not None:
        map_df = pd.DataFrame({"class_index": list(range(len(y_encoder.classes_))),
                               "class_label": y_encoder.classes_})
        st.caption("ç›®çš„å¤‰æ•°ã®ãƒ©ãƒ™ãƒ«â†’ã‚¯ãƒ©ã‚¹ç•ªå· å¯¾å¿œè¡¨")
        st.dataframe(map_df, use_container_width=True)
